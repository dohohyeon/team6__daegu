import requests
import numpy as np
import pandas as pd
import geopandas as gpd
import time
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from rapidfuzz import fuzz
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from folium import Map, CircleMarker, LayerControl, FeatureGroup
import folium
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
import pandas as pd, re, unicodedata
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from xgboost import XGBClassifier, plot_importance
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                             f1_score, roc_auc_score, classification_report,
                             make_scorer)
from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS
from xgboost import XGBClassifier
from sklearn.metrics import make_scorer, f1_score, recall_score, balanced_accuracy_score
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import f1_score, make_scorer, accuracy_score, precision_score, recall_score, roc_auc_score, classification_report
from xgboost import XGBClassifier
import optuna
import joblib
import shap
from sklearn.linear_model import LogisticRegression


df = pd.read_excel("data/dataset.xlsx", index_col="ì‹œì„¤ëª…")
dong_df = pd.read_excel("data/ìë©´ë™ë³„ë°ì´í„°1.xlsx")

df['ìë©´ë™']
dong_df['ìë©´ë™'] = dong_df["ìë©´ë™"].str.extract(r'^(?:\S+\s+){2}(\S+)')


df = df.merge(dong_df, on="ìë©´ë™", how="left")
df.columns
df.to_excel("df.xlsx", index=False)


df["êµí†µëŸ‰_ë„ë¡œí­ë¹„"] = df["êµí†µëŸ‰"] / (df["ë³´í˜¸êµ¬ì—­ë„ë¡œí­"])
df["ì–´ë¦°ì´ë°€ë„"] = df["ì–´ë¦°ì´ì¸êµ¬"] / (df["ë©´ì "])
df["ì¸êµ¬ë°€ë„"] = df["ì „ì²´ì¸êµ¬"] / (df["ë©´ì "])
df["êµí†µë°€ë„"] = df["êµí†µëŸ‰"] / (df["ë©´ì "])
df["ì†ë„_ë„ë¡œí­ë¹„"] = df["ì£¼í–‰ì†ë„"] / (df["ë³´í˜¸êµ¬ì—­ë„ë¡œí­"])
df["ì£¼ì •ì°¨ìœ„ë°˜_êµí†µëŸ‰"] = df["ë¶ˆë²•ì£¼ì •ì°¨ìœ„ë°˜"] / (df["êµí†µëŸ‰"])
df["ì£¼ì •ì°¨ìœ„ë°˜_ë„ë¡œí­"] = df["ë¶ˆë²•ì£¼ì •ì°¨ìœ„ë°˜"] / (df["êµí†µëŸ‰"])


df = df.drop(columns=['ì£¼ì†Œ','ìë©´ë™','ì–´ë¦°ì´ì¸êµ¬','ì „ì²´ì¸êµ¬','ë©´ì ',])
df.columns


# xgboostì—ì„œ ìµœì ì˜ ë³€ìˆ˜ ì„ íƒ(EFS)

# X, y ì¤€ë¹„ (ì‚¬ê³ ê±´ìˆ˜ ì œì™¸í•œ ë…ë¦½ë³€ìˆ˜ ì „ì²´)
target_col = "ì‚¬ê³ ê±´ìˆ˜"
X = df.drop(columns=[target_col])   # ì‚¬ê³ ê±´ìˆ˜ ì œì™¸
y = (df[target_col] > 0).astype(int)

# Train/Test ë¶„í•  (8:2 stratify)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì •
neg, pos = np.bincount(y_train)
scale_pos_weight = neg / pos

# -------------------
# 2) XGBoost ë¶„ë¥˜ê¸° ì •ì˜
# -------------------
xgb_clf = XGBClassifier(
    n_estimators=300,
    max_depth=4,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    scale_pos_weight=scale_pos_weight,
    eval_metric="logloss"
)

fixed_features = [
    'ì‹œì„¤ë¬¼ CCTV ìˆ˜', 'ì‹œì„¤ë¬¼ ë„ë¡œí‘œì§€íŒ ìˆ˜', 'ì‹œì„¤ë¬¼ ê³¼ì†ë°©ì§€í„± ìˆ˜',
    'ë³´í˜¸êµ¬ì—­ë„ë¡œí­', 'ìœ„ë„', 'ê²½ë„', 'ì‹ í˜¸ë“±_ë°˜ê²½300m'
]

candidates = [col for col in X_train.columns if col not in fixed_features]

# -------------------
# 2) EFSëŠ” candidatesì—ì„œë§Œ ì‹¤í–‰
# -------------------
efs = EFS(
    estimator=xgb_clf,
    min_features=1,  # ìµœì†Œ ì„ íƒ ê°œìˆ˜ ë³´ì •
    max_features=len(candidates),
    scoring=make_scorer(f1_score),
    cv=5,
    n_jobs=-1
)

efs = efs.fit(X_train[candidates], y_train)

# -------------------
# 3) ìµœì¢… ì„ íƒëœ ë³€ìˆ˜ = ê³ ì • ë³€ìˆ˜ + íƒìƒ‰ ë³€ìˆ˜ ê²°ê³¼
# -------------------
best_features = fixed_features + list(efs.best_feature_names_)
print("ìµœì  ë³€ìˆ˜ ì¡°í•©:", best_features)
print("Train êµì°¨ê²€ì¦ ìµœê³  recall-score:", efs.best_score_)

# -------------------
# 4) ìµœì  ë³€ìˆ˜ë¡œ í•™ìŠµ/í‰ê°€
# -------------------
best_model = xgb_clf.fit(X_train[best_features], y_train)

y_prob = best_model.predict_proba(X_test[best_features])[:, 1]

# 2) threshold = 0.3 ì ìš©
threshold = 0.3
y_pred = (y_prob >= threshold).astype(int)

print("\n[í…ŒìŠ¤íŠ¸ì…‹ ì„±ëŠ¥ í‰ê°€]")
print("Accuracy :", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall   :", recall_score(y_test, y_pred))
print("F1-score :", f1_score(y_test, y_pred))
print("ROC-AUC  :", roc_auc_score(y_test, y_prob))
print("\n[Classification Report]")
print(classification_report(y_test, y_pred))

import optuna
from sklearn.metrics import recall_score
from sklearn.model_selection import cross_val_score

def objective(trial):
    params = {
        "n_estimators": trial.suggest_int("n_estimators", 100, 500), # 2000
        "max_depth": trial.suggest_int("max_depth", 3, 8), # 2~ 15
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3, log=True),
        "subsample": trial.suggest_float("subsample", 0.6, 1.0), # 0.5~
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.6, 1.0), # 0.5~ 
        "min_child_weight": trial.suggest_int("min_child_weight", 1, 6), # ~ 20
        "gamma": trial.suggest_float("gamma", 0.0, 2.0), # 10
        "scale_pos_weight": scale_pos_weight,   # í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì • ê·¸ëŒ€ë¡œ ì‚¬ìš©
        "random_state": 42,
        "eval_metric": "logloss"
    }
    
    # XGBoost ë¶„ë¥˜ê¸° ìƒì„±
    model = XGBClassifier(**params)
    
    # Recall ê¸°ì¤€ 5-Fold êµì°¨ê²€ì¦
    scores = cross_val_score(
        model, X_train[best_features], y_train,
        cv=5,
        scoring=make_scorer(f1_score)
    )
    return scores.mean()

# -------------------
# 6) Optuna ì‹¤í–‰
# -------------------
study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=100)   # íƒìƒ‰ íšŸìˆ˜ ì¡°ì • ê°€ëŠ¥ (ì˜ˆ: 50~100)

print("Best params:", study.best_params)
print("Best CV Recall:", study.best_value)

# -------------------
# 7) ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ í•™ìŠµ
# -------------------
best_params = study.best_params
best_params.update({"scale_pos_weight": scale_pos_weight, "random_state": 42, "eval_metric": "logloss"})

best_model = XGBClassifier(**best_params)
best_model.fit(X_train[best_features], y_train)

# -------------------
# 8) í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ (threshold=0.3)
# -------------------
y_prob = best_model.predict_proba(X_test[best_features])[:, 1]
threshold = 0.5
y_pred = (y_prob >= threshold).astype(int)

print("\n[í…ŒìŠ¤íŠ¸ì…‹ ì„±ëŠ¥ í‰ê°€ - Optuna ìµœì  íŒŒë¼ë¯¸í„°]")
print("Accuracy :", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall   :", recall_score(y_test, y_pred))
print("F1-score :", f1_score(y_test, y_pred))
print("ROC-AUC  :", roc_auc_score(y_test, y_prob))
print("\n[Classification Report]")
print(classification_report(y_test, y_pred, digits=3))

best_features
df.columns


# -------------------
# 1) ë°ì´í„° ì¤€ë¹„
# -------------------
target_col = "ì‚¬ê³ ê±´ìˆ˜"
best_features = ['ì‹œì„¤ë¬¼ CCTV ìˆ˜', 'ì‹œì„¤ë¬¼ ë„ë¡œí‘œì§€íŒ ìˆ˜', 'ì‹œì„¤ë¬¼ ê³¼ì†ë°©ì§€í„± ìˆ˜',
                 'ë³´í˜¸êµ¬ì—­ë„ë¡œí­', 'ìœ„ë„', 'ê²½ë„', 'ì‹ í˜¸ë“±_ë°˜ê²½300m', 'ë¶ˆë²•ì£¼ì •ì°¨ìœ„ë°˜', 'ê²½ì‚¬ë„',
                 'ë©´ì ', 'ì£¼í–‰ì†ë„', 'ì–´ë¦°ì´ë°€ë„', 'ì¸êµ¬ë°€ë„']


X = df[best_features]
y = (df[target_col] > 0).astype(int)

# Train/Test ë¶„í•  (8:2, stratify)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì • weight
neg, pos = np.bincount(y_train)
scale_pos_weight = neg / pos

# -------------------
# 2) Optuna objective í•¨ìˆ˜ ì •ì˜
# -------------------
def objective(trial):
    params = {
        "n_estimators": trial.suggest_int("n_estimators", 200, 2000),
        "max_depth": trial.suggest_int("max_depth", 2, 15),
        "learning_rate": trial.suggest_float("learning_rate", 1e-4, 0.3, log=True),
        "subsample": trial.suggest_float("subsample", 0.5, 1.0),
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.5, 1.0),
        "min_child_weight": trial.suggest_int("min_child_weight", 1, 20),
        "gamma": trial.suggest_float("gamma", 0.0, 10.0),
        "scale_pos_weight": scale_pos_weight,
        "random_state": 42,
        "eval_metric": "logloss",
        "use_label_encoder": False
    }

    model = XGBClassifier(**params)
    scores = cross_val_score(
        model, X_train, y_train,
        cv=5,
        scoring=make_scorer(f1_score)
    )
    return scores.mean()

# -------------------
# 3) Optuna ì‹¤í–‰
# -------------------
study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=100)  # íƒìƒ‰ íšŸìˆ˜ ì¡°ì • ê°€ëŠ¥

print("Best params:", study.best_params)
print("Best CV f1-score:", study.best_value)

# -------------------
# 4) ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ í•™ìŠµ
# -------------------
best_params = study.best_params
best_params.update({
    "scale_pos_weight": scale_pos_weight,
    "random_state": 42,
    "eval_metric": "logloss",
    "use_label_encoder": False
})

best_model = XGBClassifier(**best_params)
best_model.fit(X_train, y_train)

# -------------------
# 5) í…ŒìŠ¤íŠ¸ì…‹ í‰ê°€
# -------------------
y_prob = best_model.predict_proba(X_test)[:, 1]
threshold = 0.5  # ì›í•˜ëŠ” threshold
y_pred = (y_prob >= threshold).astype(int)

print("\n[í…ŒìŠ¤íŠ¸ì…‹ ì„±ëŠ¥ í‰ê°€ - Optuna ìµœì  íŒŒë¼ë¯¸í„°]")
print("Accuracy :", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall   :", recall_score(y_test, y_pred))
print("F1-score :", f1_score(y_test, y_pred))
print("ROC-AUC  :", roc_auc_score(y_test, y_prob))
print("\n[Classification Report]")
print(classification_report(y_test, y_pred, digits=3))

# -------------------
# 6) ëª¨ë¸ ì €ì¥ (ì˜µì…˜)
# -------------------
joblib.dump(best_model, "best_model.pkl")
print("ëª¨ë¸ ì €ì¥ ì™„ë£Œ: best_model.pkl")


# Logistic Regression

df = pd.read_excel("data/dataset.xlsx", index_col="ì‹œì„¤ëª…")
dong_df = pd.read_excel("data/ìë©´ë™ë³„ë°ì´í„°1.xlsx")

df['ìë©´ë™']
dong_df['ìë©´ë™'] = dong_df["ìë©´ë™"].str.extract(r'^(?:\S+\s+){2}(\S+)')


df = df.merge(dong_df, on="ìë©´ë™", how="left")

df["êµí†µëŸ‰_ë„ë¡œí­ë¹„"] = df["êµí†µëŸ‰"] / (df["ë³´í˜¸êµ¬ì—­ë„ë¡œí­"])
df["ì–´ë¦°ì´ë°€ë„"] = df["ì–´ë¦°ì´ì¸êµ¬"] / (df["ë©´ì "])
df["êµí†µë°€ë„"] = df["êµí†µëŸ‰"] / (df["ë©´ì "])
df["ì†ë„_ë„ë¡œí­ë¹„"] = df["ì£¼í–‰ì†ë„"] / (df["ë³´í˜¸êµ¬ì—­ë„ë¡œí­"])

df = df.drop(columns=['ì£¼ì†Œ','ìë©´ë™'])
target_col = "ì‚¬ê³ ê±´ìˆ˜"
best_features = [
    'ì‹œì„¤ë¬¼ CCTV ìˆ˜', 'ì‹œì„¤ë¬¼ ë„ë¡œí‘œì§€íŒ ìˆ˜', 'ì‹œì„¤ë¬¼ ê³¼ì†ë°©ì§€í„± ìˆ˜',
    'ë³´í˜¸êµ¬ì—­ë„ë¡œí­', 'ìœ„ë„', 'ê²½ë„', 'ì‹ í˜¸ë“±_ë°˜ê²½300m',
    'ê²½ì‚¬ë„', 'ë©´ì ', 'êµí†µëŸ‰', 'ì£¼í–‰ì†ë„', 'ì–´ë¦°ì´ë°€ë„'
]

X = df[best_features]
y = (df[target_col] > 0).astype(int)

# Train/Test ë¶„í•  (8:2 stratify)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# -------------------
# 2) Optuna objective í•¨ìˆ˜ ì •ì˜
# -------------------
def objective(trial):
    params = {
        "C": trial.suggest_float("C", 1e-3, 100, log=True),  # ê·œì œ ê°•ë„
        "penalty": trial.suggest_categorical("penalty", ["l1", "l2"]),  # ê·œì œ ë°©ì‹
        "solver": trial.suggest_categorical("solver", ["liblinear", "saga"]),  
        "max_iter": 1000,
        "class_weight": "balanced",
        "random_state": 42
    }

    model = LogisticRegression(**params)
    scores = cross_val_score(
        model, X_train, y_train,
        cv=5,
        scoring=make_scorer(f1_score)
    )
    return scores.mean()

# -------------------
# 3) Optuna ì‹¤í–‰
# -------------------
study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=50)  # Logisticì€ ê°€ë³ê¸° ë•Œë¬¸ì— 50íšŒë©´ ì¶©ë¶„

print("Best params:", study.best_params)
print("Best CV f1-score:", study.best_value)

# -------------------
# 4) ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ í•™ìŠµ
# -------------------
best_params = study.best_params
best_params.update({
    "max_iter": 1000,
    "class_weight": "balanced",
    "random_state": 42
})

best_model = LogisticRegression(**best_params)
best_model.fit(X_train, y_train)

# -------------------
# 5) í…ŒìŠ¤íŠ¸ì…‹ í‰ê°€
# -------------------
y_prob = best_model.predict_proba(X_test)[:, 1]
threshold = 0.  # ì›í•˜ëŠ” threshold
y_pred = (y_prob >= threshold).astype(int)

print("\n[í…ŒìŠ¤íŠ¸ì…‹ ì„±ëŠ¥ í‰ê°€ - Optuna ìµœì  íŒŒë¼ë¯¸í„°]")
print("Accuracy :", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall   :", recall_score(y_test, y_pred))
print("F1-score :", f1_score(y_test, y_pred))
print("ROC-AUC  :", roc_auc_score(y_test, y_prob))
print("\n[Classification Report]")
print(classification_report(y_test, y_pred, digits=3))

# íšŒê·€ê³„ìˆ˜ ì¶”ì¶œ
coef_df = pd.DataFrame({
    "Feature": best_features,
    "Coefficient": best_model.coef_[0]
})

# ì ˆí¸(Intercept)
intercept = best_model.intercept_[0]
coef_df.sort_values('Coefficient', ascending=False)


print("Intercept:", intercept)
print("\níšŒê·€ê³„ìˆ˜:")
print(coef_df)









# 1) ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
loaded_model = joblib.load("best_model.pkl")

# 2) ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ì˜ˆì¸¡ ìˆ˜í–‰
#    í™•ë¥  ì˜ˆì¸¡ (y=1ì¼ í™•ë¥ )
df["y_prob"] = loaded_model.predict_proba(df[best_features])[:, 1]
df["ìœ„í—˜ë„ì ìˆ˜"] = np.round(df["y_prob"] * 100, 0).astype(int)

df.to_csv("ì ìˆ˜í¬í•¨.csv", index=False, encoding="utf-8-sig")



plt.rc("font", family="Malgun Gothic")   # ë§‘ì€ ê³ ë”•
plt.rc("axes", unicode_minus=False)  # ë§ˆì´ë„ˆìŠ¤(-) ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

import matplotlib.pyplot as plt
from sklearn.inspection import PartialDependenceDisplay

loaded_model = joblib.load("best_model.pkl")

# 2) PDPë¥¼ ê·¸ë¦¬ê³  ì‹¶ì€ ë³€ìˆ˜ë“¤ ì§€ì • (ì˜ˆì‹œ: 2ê°œ ë³€ìˆ˜)
features_to_plot = ['ì‹œì„¤ë¬¼ CCTV ìˆ˜',
 'ì‹œì„¤ë¬¼ ë„ë¡œí‘œì§€íŒ ìˆ˜',
 'ì‹œì„¤ë¬¼ ê³¼ì†ë°©ì§€í„± ìˆ˜',
 'ë³´í˜¸êµ¬ì—­ë„ë¡œí­',
 'ìœ„ë„',
 'ê²½ë„',
 'ì‹ í˜¸ë“±_ë°˜ê²½300m',
 'ê²½ì‚¬ë„',
 'ë©´ì ',
 'êµí†µëŸ‰',
 'ì£¼í–‰ì†ë„',
 'ì–´ë¦°ì´ë°€ë„']

# 3) PDP Plot
fig, ax = plt.subplots(figsize=(20, 12))
PartialDependenceDisplay.from_estimator(
    estimator=loaded_model,             # ë¶ˆëŸ¬ì˜¨ ëª¨ë¸
    X=X_train[best_features],           # í•™ìŠµì— ì‚¬ìš©í•œ ë…ë¦½ë³€ìˆ˜ ë°ì´í„°
    features=features_to_plot,          # PDP ë³´ê³  ì‹¶ì€ ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸
    percentiles=(0.05, 0.95),           # ê·¹ë‹¨ê°’ ì œì™¸
    ax=ax
)

plt.suptitle("Partial Dependence Plot", fontsize=16)
plt.tight_layout()
plt.show()


# 1) ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
loaded_model = joblib.load("best_model.pkl")

# 2) SHAP explainer ìƒì„± (Tree ê¸°ë°˜ ëª¨ë¸ ì „ìš©)
explainer = shap.TreeExplainer(loaded_model)

# 3) SHAP value ê³„ì‚° (ì˜ˆ: í…ŒìŠ¤íŠ¸ì…‹ ê¸°ì¤€)
shap_values = explainer.shap_values(X_test[best_features])

# -----------------------------
# ğŸ“Š (1) Summary Plot (dot plot)
# -----------------------------
plt.figure(figsize=(10,6))
shap.summary_plot(shap_values, X_test[best_features], show=False)
plt.title("SHAP Summary Plot (ë³€ìˆ˜ë³„ ê¸°ì—¬ë„ ë¶„í¬)", fontsize=14)
plt.tight_layout()
plt.show()

# -----------------------------
# ğŸ“Š (2) Bar Plot (í‰ê·  ì ˆëŒ“ê°’ ì¤‘ìš”ë„)
# -----------------------------
plt.figure(figsize=(8,6))
shap.summary_plot(shap_values, X_test[best_features], plot_type="bar", show=False)
plt.title("SHAP Bar Plot (ë³€ìˆ˜ë³„ í‰ê·  ì¤‘ìš”ë„)", fontsize=14)
plt.tight_layout()
plt.show()

# -----------------------------
# ğŸ“Š (3) Dependence Plot (íŠ¹ì • ë³€ìˆ˜)
# -----------------------------
shap.dependence_plot("êµí†µëŸ‰", shap_values, X_test[best_features])

# -----------------------------
# ğŸ“Š (4) Force Plot (ê°œë³„ ìƒ˜í”Œ)
# -----------------------------
i = 0  # ìƒ˜í”Œ ì¸ë±ìŠ¤
shap.force_plot(
    explainer.expected_value,
    shap_values[i],
    X_test[best_features].iloc[i],
    matplotlib=True
)

# -----------------------------
# ğŸ“Š (5) Waterfall Plot (ê°œë³„ ìƒ˜í”Œ)
# -----------------------------
shap.plots.waterfall(
    shap.Explanation(
        values=shap_values[i],
        base_values=explainer.expected_value,
        data=X_test[best_features].iloc[i].values,
        feature_names=X_test[best_features].columns
    )
)